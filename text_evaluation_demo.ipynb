{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FiftyOne Text Evaluation Metrics Plugin\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harpreetsahota204/text_evaluation_metrics/blob/main/text_evaluation_demo.ipynb)\n",
    "\n",
    "This notebook demonstrates the **Text Evaluation Metrics** plugin for FiftyOne.\n",
    "\n",
    "## Available Metrics\n",
    "\n",
    "1. **ANLS** - Average Normalized Levenshtein Similarity (primary VLM OCR metric)\n",
    "2. **Exact Match** - Binary exact match accuracy\n",
    "3. **Normalized Similarity** - Continuous similarity without threshold\n",
    "4. **CER** - Character Error Rate\n",
    "5. **WER** - Word Error Rate\n",
    "\n",
    "üîó [GitHub Repository](https://github.com/harpreetsahota204/text_evaluation_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, install FiftyOne and the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q fiftyone python-Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the Plugin\n",
    "\n",
    "Download and install the plugin directly from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fiftyone plugins download https://github.com/harpreetsahota204/text_evaluation_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import libraries and check versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.operators as foo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from fiftyone.utils.huggingface import load_from_hub\n",
    "\n",
    "dataset = load_from_hub(\"harpreetsahota/visual_ai_at_neurips2025_jina_with_ocr\", persistent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Compute ANLS\n",
    "\n",
    "**ANLS** is the primary metric for VLM OCR evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anls_op = foo.get_operator(\"@harpreetsahota/text-evaluation-metrics/compute_anls\")\n",
    "\n",
    "result = anls_op(\n",
    "    dataset, \n",
    "    pred_field=\"md_abstract\", \n",
    "    gt_field=\"abstract\", \n",
    "    output_field=\"md_anls\"\n",
    "    threshold=0.5,\n",
    "    delegate=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Compute Exact Match\n",
    "\n",
    "**Exact Match** returns 1.0 only for perfect matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_op = foo.get_operator(\"@harpreetsahota/text-evaluation-metrics/compute_exact_match\")\n",
    "\n",
    "result = em_op(\n",
    "    dataset, \n",
    "    pred_field=\"md_abstract\", \n",
    "    gt_field=\"abstract\",\n",
    "    output_field=\"md_exact_match\",\n",
    "    delegate=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Compute Normalized Similarity\n",
    "\n",
    "**Normalized Similarity** provides continuous scores without threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_op = foo.get_operator(\"@harpreetsahota/text-evaluation-metrics/compute_normalized_similarity\")\n",
    "\n",
    "result = sim_op(\n",
    "    dataset, \n",
    "    pred_field=\"md_abstract\", \n",
    "    gt_field=\"abstract\",\n",
    "    output_field=\"md_norm_sim\",\n",
    "    delegate=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Compute CER (Character Error Rate)\n",
    "\n",
    "**CER** measures character-level edits needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_op = foo.get_operator(\"@harpreetsahota/text-evaluation-metrics/compute_cer\")\n",
    "\n",
    "result = cer_op(\n",
    "    dataset, \n",
    "    pred_field=\"md_abstract\", \n",
    "    gt_field=\"abstract\",\n",
    "    output_field=\"md_cer\",\n",
    "    delegate=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Compute WER (Word Error Rate)\n",
    "\n",
    "**WER** measures word-level edits needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_op = foo.get_operator(\"@harpreetsahota/text-evaluation-metrics/compute_wer\")\n",
    "\n",
    "result = wer_op(\n",
    "    dataset, \n",
    "    pred_field=\"md_abstract\", \n",
    "    gt_field=\"abstract\",\n",
    "    output_field=\"md_wer\"\n",
    "    delegate=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated all 5 text evaluation metrics.\n",
    "\n",
    "### Key Takeaways\n",
    "- **ANLS** is the primary metric for VLM OCR tasks\n",
    "- **Exact Match** provides a strict accuracy baseline\n",
    "- **Normalized Similarity** helps understand error distribution\n",
    "- **CER/WER** provide detailed error analysis\n",
    "\n",
    "### Resources\n",
    "- üìö [Plugin Documentation](https://github.com/harpreetsahota204/text_evaluation_metrics)\n",
    "- üåê [FiftyOne Docs](https://docs.voxel51.com/)\n",
    "\n",
    "**Author:** Harpreet Sahota | **License:** Apache 2.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
